{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Applied Data Science Capstone: Segementing and Clustering Neighborhoods in SF"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1. Introduction\nYou and your partner have been together for over a year now. They decide on the location everytime you both go out. This past week, your partner mentioned how they would like you to plan a day in the city. Your mind is blank. You don't much about the city, yet any activities to do there. Luckily for you, you have the demonstrated ability to solve this problem by applying the skills you've learned working to achieve IBM's Data Science Profession Certificate. Yes, you is me."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1.1. Business Problem\nNo business problem, just a personal problem :)\n\nJust kidding. There is one underlying theme I would like to get across and that is the importance of location in a business. The location of a business has been and always will be important. A business's location not only attracts their customers but also plays an essential role in attracting and retaining the best employees, many of whom prioritize location in order to optimize work-life balance. Real estate cost is the second largest expense of a business after labor costs, so naturally finding a location with optimal real estate cost is efficient for a business. Lasty, factors in city ordinance and accessibility will be crucial for a business location. What kind of laws and regulations will your business be operating under? Will the business have access to new markets, customers and resources?\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2. Data\nIn order to make the best possible decision, we will need to acquire some data. \n- [San Francisco Neighborhood Data](https://data.sfgov.org/Geographic-Locations-and-Boundaries/Analysis-Neighborhoods/p5b7-5n3h)\n- [San Francisco Crime Data](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783)\n- [Foursquare Data](https://foursquare.com/developers/apps)\n\nBut before we move on further, let's get the required libraries needed for this project."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Installing and importing the required libraries**"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: | \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - defaults/noarch::ibm-wsrt-py37main-main==custom=2155\n  - defaults/noarch::ibm-wsrt-py37main-keep==0.0.0=2155\n  - conda-forge/linux-64::pytorch==1.8.0=cpu_py37ha70c682_1\ndone\n\n# All requested packages already installed.\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: \\ \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - defaults/noarch::ibm-wsrt-py37main-main==custom=2155\n  - defaults/noarch::ibm-wsrt-py37main-keep==0.0.0=2155\n  - conda-forge/linux-64::pytorch==1.8.0=cpu_py37ha70c682_1\ndone\n\n# All requested packages already installed.\n\nLibraries imported.\n"
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\n%matplotlib inline \nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering library\n\nfrom itertools import chain\n\nfrom IPython.core.display import HTML\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1. San Francisco Neighborhood Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Importing San Francisco Neighborhood Data**"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>the_geom</th>\n      <th>NHOOD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MULTIPOLYGON (((-122.38157774241415 37.7530704...</td>\n      <td>Bayview Hunters Point</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MULTIPOLYGON (((-122.40361299982803 37.7493370...</td>\n      <td>Bernal Heights</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MULTIPOLYGON (((-122.42655500055683 37.7694849...</td>\n      <td>Castro/Upper Market</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MULTIPOLYGON (((-122.4062259995664 37.79755900...</td>\n      <td>Chinatown</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MULTIPOLYGON (((-122.42398200023331 37.7315519...</td>\n      <td>Excelsior</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                            the_geom                  NHOOD\n0  MULTIPOLYGON (((-122.38157774241415 37.7530704...  Bayview Hunters Point\n1  MULTIPOLYGON (((-122.40361299982803 37.7493370...         Bernal Heights\n2  MULTIPOLYGON (((-122.42655500055683 37.7694849...    Castro/Upper Market\n3  MULTIPOLYGON (((-122.4062259995664 37.79755900...              Chinatown\n4  MULTIPOLYGON (((-122.42398200023331 37.7315519...              Excelsior"
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Cleaning up San Francisco Neighborhood Data**"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/ipykernel/__main__.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  from ipykernel import kernelapp as app\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/ipykernel/__main__.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  app.launch_new_instance()\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The dataframe has 42667 entries and 41 unique neighborhoods.\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.753070</td>\n      <td>-122.381578</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.753061</td>\n      <td>-122.381569</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.753094</td>\n      <td>-122.381592</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.753046</td>\n      <td>-122.381556</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.753041</td>\n      <td>-122.381551</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "            Neighborhood   Latitude   Longitude\n0  Bayview Hunters Point  37.753070 -122.381578\n1  Bayview Hunters Point  37.753061 -122.381569\n2  Bayview Hunters Point  37.753094 -122.381592\n3  Bayview Hunters Point  37.753046 -122.381556\n4  Bayview Hunters Point  37.753041 -122.381551"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_sfneighborhoods['the_geom'] =  df_sfneighborhoods['the_geom'].map(lambda x: x.lstrip('MULTIPOLYGON ()').rstrip('()'))\ndf_sfneighborhoods['the_geom'] = df_sfneighborhoods['the_geom'].str.replace('\\)\\)', '')\ndf_sfneighborhoods['the_geom'] = df_sfneighborhoods['the_geom'].str.replace('\\(\\(', '')\n\n# swap two columns\ncolumns_titles = ['NHOOD','the_geom']\ndf_sfneighborhoods = df_sfneighborhoods.reindex(columns=columns_titles)\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split(',')))\n\n# calculate lengths of splits\nlens = df_sfneighborhoods['the_geom'].str.split(',').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf_sfneighborhoods_geo= pd.DataFrame({'NHOOD': np.repeat(df_sfneighborhoods['NHOOD'], lens),\n                    'the_geom': chainer(df_sfneighborhoods['the_geom'])})\n\n# split the_geom into Longitude and Latitude\ndf_sfneighborhoods_geo[['Longitude','Latitude']] = df_sfneighborhoods_geo.the_geom.str.split(expand=True) \ndf_sfneighborhoods_geo.head()\n\n# rename NHOOD drop the_geom column and swap the Lon and Lat column\ndf_sfneighborhoods_geo = df_sfneighborhoods_geo[['NHOOD','Latitude','Longitude']]\ndf_sfneighborhoods_geo.columns = ['Neighborhood','Latitude', 'Longitude']\ndf_sfneighborhoods_geo = df_sfneighborhoods_geo.reset_index(drop=True)\n\n# convert str to float\ndf_sfneighborhoods_geo['Latitude'] = pd.to_numeric(df_sfneighborhoods_geo['Latitude'],errors='coerce')\ndf_sfneighborhoods_geo['Longitude'] = pd.to_numeric(df_sfneighborhoods_geo['Longitude'],errors='coerce')\n\nprint(('The dataframe has {} entries and {} unique neighborhoods.').format((df_sfneighborhoods_geo.shape[0]),len(df_sfneighborhoods_geo['Neighborhood'].unique())))\ndf_sfneighborhoods_geo.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Notice how there are only 41 unique neighborhoods but 42667 entries. This can be fixed by getting the mean latitude and longitude of each neighborhood."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Getting the mean latitiude and longitude of each neighborhood**"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bayview Hunters Point</td>\n      <td>37.725117</td>\n      <td>-122.379168</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bernal Heights</td>\n      <td>37.741461</td>\n      <td>-122.414034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Castro/Upper Market</td>\n      <td>37.761351</td>\n      <td>-122.437652</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chinatown</td>\n      <td>37.796295</td>\n      <td>-122.407744</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excelsior</td>\n      <td>37.719165</td>\n      <td>-122.431970</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "            Neighborhood   Latitude   Longitude\n0  Bayview Hunters Point  37.725117 -122.379168\n1         Bernal Heights  37.741461 -122.414034\n2    Castro/Upper Market  37.761351 -122.437652\n3              Chinatown  37.796295 -122.407744\n4              Excelsior  37.719165 -122.431970"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_latitudemean = df_sfneighborhoods_geo.groupby(\"Neighborhood\").Latitude.mean().reset_index()\ndf_longitudemean = df_sfneighborhoods_geo.groupby(\"Neighborhood\").Longitude.mean().reset_index()\ndf_sfneighborhood = pd.merge(left=df_latitudemean, right=df_longitudemean, left_on='Neighborhood', right_on='Neighborhood')\ndf_sfneighborhood.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.2. San Francisco Crime Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Importing San Francisco Crime Data**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Cleaning up San Francisco Crime Data**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sfcrime_filtered = sfcrime[['Analysis Neighborhood','Incident Category', 'Incident Date']]\n\n#drop all null values\nsfcrime_filtered_dropna = sfcrime_filtered.dropna()\n\n#convert incident date to datetime\nsfcrime_filtered_dropna['Incident Date'] = sfcrime_filtered_dropna['Incident Date'].astype('datetime64[ns]') \n\n#filter to just crimes in the last 5 years, as the neighborhoods in san francisco are rapidly changing and being gentrified, we want data that is relevant to today's crime.\nsfcrime_filtered_dropna_2020 = sfcrime_filtered_dropna.loc[sfcrime_filtered_dropna['Incident Date'] > '2020-01-01']\n\n#change the name of 'Analysis Neighborhood' to 'Neighborhood'\nsfcrime_filtered_dropna_2020.rename(columns={'Analysis Neighborhood': 'Neighborhood'}, inplace = True)\n\nsfcrime_filtered_dropna_2020.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.3. Foursquare Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Foursquare credentials needed to make API calls for venue information.  \n**Defining Foursquare Credentials**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Methodology"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.1. Exploratory Data Analysis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Counting the number of crimes in each neighborhood**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#count the number of crimes in each neighborhood\nsfcrime_filtered_dropna_2020_grouped = sfcrime_filtered_dropna_2020.groupby('Neighborhood', as_index=False).count()\n\n#remove the column Incident Date\nsfcrime_filtered_dropna_2020_grouped.drop(columns = 'Incident Date',inplace = True)\n\n#rename the column Incident Category to Incidents\nsfcrime_filtered_dropna_2020_grouped.rename(columns={'Incident Category': 'Incidents'}, inplace = True)\n\n#join neighborhood and crimes dataframe\ndf_merge = pd.merge(left=df_sfneighborhood, right=sfcrime_filtered_dropna_2020_grouped, left_on='Neighborhood', right_on='Neighborhood', left_index=False, right_index=False)\ndf_merge.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Finding the neighborhoods with the least amount of crime**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_final = df_merge.sort_values(by= ['Incidents'], ascending = True)\ndf_final.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Finding the neighborhoods with the most amount of crime**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_final = df_merge.sort_values(by= ['Incidents'], ascending = False)\ndf_final.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Using Matplotlib to visualize crime rate in our neighborhoods**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_final.plot.bar(x = 'Neighborhood', y = 'Incidents', title = \"Crime Incidents by Neighborhood\", legend = None, rot= 45, figsize = (30, 12), color=['slategrey', 'lightsteelblue', 'cornflowerblue', 'royalblue'])\nplt.ylabel('Number of Reported Crimes', fontsize=12)\nplt.xticks(fontsize=12)\nplt.xlabel('Neighborhood', fontsize = 12)\nplt.title('Number of Reported Crimes by Neighborhood', fontsize = 14)\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.2. Folium Mapping"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Using geopy library to get the latitude and longitude values of San Francisco**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = \"San Francisco, CA\"\n\ngeolocator = Nominatim(user_agent=\"san_francisco_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of San Francisco city are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Folium mapping will help visualize the location of each neighbourhood around San Francisco.  \n**Creating a map of San Francisco with neighborhoods superimposed on top**  "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of San Francisco using latitude and longitude values\nmap_sf = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, neighborhood in zip(df_final['Latitude'], df_final['Longitude'], df_final['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_sf)  \nmap_sf "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "HTML(map_sf._repr_html_()) #to render map on github due to compatabilty issue"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.3. Foursquare Analysis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Defining a function to search for the most popular venues within a 0.5 mile radius of our neighborhoods.**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    venues_list=[]\n    \n    for name, lat, lng in zip(names, latitudes, longitudes):\n        # print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n \n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Searching for the most popular venues within a 0.5 mile radius of our neighborhoods**  \nnote: The limit of number of venues returned by Foursquare API is 100."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "SF_venues = getNearbyVenues(names=df_final['Neighborhood'],\n                                   latitudes=df_final['Latitude'],\n                                   longitudes=df_final['Longitude'])\nSF_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(SF_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Checking how many venues were returned for each neighborhood**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "SF_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Further analysis with one hot encoding**  \nOne hot encoding allows the representation of categorical data to be more expressive. Many machine learning algorithms cannot work with categorical data directly so the categories must be converted into numbers."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\nSF_venues_onehot = pd.get_dummies(SF_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nSF_venues_onehot['Neighborhood'] = SF_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [SF_venues_onehot.columns[-1]] + list(SF_venues_onehot.columns[:-1])\nSF_venues_onehot = SF_venues_onehot[fixed_columns]\n\nSF_venues_onehot.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Grouping rows by neighborhood and by taking the mean of the frequency of occurrence of each category**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "SF_venues_grouped = SF_venues_onehot.groupby('Neighborhood').mean().reset_index()\nSF_venues_grouped.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Identifying the top 5 venues of each neighborhood and the frequency of each venue category**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# print each neighborhood along with the top 5 most common venues\nnum_top_venues = 5\n\nfor hood in SF_venues_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = SF_venues_grouped[SF_venues_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Putting Foursquare data into a dataframe and identifying the most common venues in each neighborhood**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    return row_categories_sorted.index.values[0:num_top_venues]\n\nnum_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = SF_venues_grouped['Neighborhood']\n\nfor ind in np.arange(SF_venues_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(SF_venues_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3.4. Neighborhood Cluster Analysis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Run k-means to cluster the neighborhood into 5 clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 5\n\nSF_grouped_clustering = SF_venues_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(SF_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Creating a new dataframe that includes the cluster as well as the top 10 venue category for each neighborhood**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\ndf_merged = df_final\ndf_merged = df_final.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\ndf_merged.head() # check the last columns!"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Visualizing the neighborhood clusters**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(\n        df_merged['Latitude'], \n        df_merged['Longitude'], \n        df_merged['Neighborhood'], \n        df_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters\nHTML(map_clusters._repr_html_()) #to render map on github due to compatabilty issue"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Analyzing the neighborhood clusters**"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": " df_merged.loc[df_merged['Cluster Labels'] == 0,df_merged.columns[[0] + list(range(5, df_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": " df_merged.loc[df_merged['Cluster Labels'] == 1,df_merged.columns[[0] + list(range(5, df_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": " df_merged.loc[df_merged['Cluster Labels'] == 2, df_merged.columns[[0] + list(range(5, df_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": " df_merged.loc[df_merged['Cluster Labels'] == 3,df_merged.columns[[0] + list(range(5, df_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": " df_merged.loc[df_merged['Cluster Labels'] == 4, df_merged.columns[[0] + list(range(5, df_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Reults and Discussion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We were able to access San Francisco crime data and with this information we were able to identify the top neighborhoods with the highest crime numbers and the neighborhoods with the lowest crime numbers. However, it is important to note when comparing crime rates across neighborhoods that not all neighborhoods are equal in size and population. While neighborhood X has more crime frequency than neighborhood Y, it does not mean neighborhood X has a higher crime rate than neighborhood Y. This is to be considered in the analysis. Our analysis has informed us that: \n- Beaches, Parks, and Trails are the most common venue category in neighborhoods with the least amount of crime. \n- Restaurants, Cafes, Nightclubs, and Bars are the most common venue category in neighborhoods with the most amount of crime.\n- Chinatown, Hayes Valley, Nob Hill, Tenderloin, and Japantown are neighborhoods with the most venues.\n\nBased on the analysis, I would take my partner to Golden Gate Park due to its top 2 venue category being parks and thrift stores which they highly enjoy. Japantown also seems to be a very suitable option due to its high venue count with low crime frequency. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 5. Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This study aimed to explore, segement, and cluster the neighborhoods of San Francisco.The analysis was conducted using python libraries to process data, Foursquare API to retrive venues in San Francisco neighborhoods, and Folium to visualize, cluster, and segment neighborhoods."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}